{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0baafaa-cc65-481e-a8a2-1c0b3ed3a365",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Genetic Algorithm for Allocating a Progressive Carbon Dividend\n",
    "                                    \n",
    "# please note that NVIDIA RAPIDS libraries cannot be used without an NVIDIA GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huge thanks to Ahmed F. Gad for creating \"pygad\", an open source python library that provided the framework to set up my genetic algorithm\n",
    "\n",
    "# Pygad Cite:\n",
    "\n",
    "# @article{gad2023pygad,\n",
    "#   title={Pygad: An intuitive genetic algorithm python library},\n",
    "#   author={Gad, Ahmed Fawzy},\n",
    "#   journal={Multimedia Tools and Applications},\n",
    "#   pages={1--14},\n",
    "#   year={2023},\n",
    "#   publisher={Springer}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd    \n",
    "from dask_ml.model_selection import train_test_split\n",
    "import pygad\n",
    "import xgboost as xgb \n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from dask_ml.ensemble import BlockwiseVotingRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import time\n",
    "import cuml\n",
    "import cudf\n",
    "import dask\n",
    "import dask_cudf as dc\n",
    "dask.config.set({\"dataframe.backend\": \"cudf\"})\n",
    "dask.config.set({'large-graph-warning-threshold': False})\n",
    "from cuml.ensemble import RandomForestRegressor as cuRF\n",
    "from dask_ml.model_selection import GridSearchCV \n",
    "import dask_cudf\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import dask.distributed\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import cupy as cp\n",
    "from cuml import ForestInference\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask_cuda\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "cluster = dask_cuda.LocalCUDACluster(n_workers=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.random.seed(seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hj1o2UpC1VOl",
    "outputId": "b0e7353b-a8e5-4cf9-babc-ad79f28981ea"
   },
   "outputs": [],
   "source": [
    "# Survey data cleaning and analysis\n",
    "\n",
    "# SHED 2022, https://www.federalreserve.gov/consumerscommunities/shed_data.htm\n",
    "df = pd.read_excel(r\"SHED_2022_Cleaned.xlsx\", index_col='CaseID')\n",
    "\n",
    "# See the data cleaning file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33aca0fe-ece6-4931-9aaf-33e954ea3950",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indicator_distance_from_poverty(df):\n",
    "    poverty_line_2024 = 15060  # Poverty line for 1 person household (2024)\n",
    "    # https://aspe.hhs.gov/topics/poverty-economic-mobility/poverty-guidelines\n",
    "    distance_from_poverty = (df[\"per_person_income\"] / poverty_line_2024) * 100\n",
    "    return distance_from_poverty\n",
    "                \n",
    "percentages = indicator_distance_from_poverty(df)\n",
    "percentages = percentages.round(3)\n",
    "df[\"distance_from_poverty\"] = percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "526d2a86-1b5f-4c06-8f25-384468a56088",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indicator_distance_from_mean_income(df):\n",
    "    mean_income = da.mean(df[\"per_person_income\"]).compute()\n",
    "    distance_from_mean_income = (df[\"per_person_income\"] / mean_income) * 100\n",
    "    return distance_from_mean_income\n",
    "\n",
    "percentages = indicator_distance_from_mean_income(df)\n",
    "percentages = percentages.round(3)\n",
    "df[\"distance_from_mean_income\"] = percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification indicator\n",
    "df['FSRI Score'].describe()\n",
    "df[\"target\"] = np.select(\n",
    "    [df[\"FSRI Score\"] >= 0.77,\n",
    "     (df[\"FSRI Score\"] >= 0.64) & (df[\"FSRI Score\"] <= 0.77),\n",
    "     (df[\"FSRI Score\"] >= 0.476250) & (df[\"FSRI Score\"] <= 0.64),\n",
    "     df[\"FSRI Score\"] <= 0.476250],\n",
    "    [\"Extremely Stable\", \"Somewhat Stable\", \"Somewhat Unstable\", \"Extremely Unstable\"]\n",
    ")\n",
    "\n",
    "categories = [\"Extremely Unstable\",\"Somewhat Unstable\",\"Somewhat Stable\",\"Extremely Stable\"]\n",
    "oe = OrdinalEncoder(categories = [categories])\n",
    "df[\"target\"] = oe.fit_transform(df[[\"target\"]])\n",
    "df[\"target\"]\n",
    "# 0: Extremely Unstable\n",
    "# 1: Somewhat Unstable\n",
    "# 2: Somewhat Stable\n",
    "# 3: Extremely Stable\n",
    "\n",
    "X_class = df[[\"D1A\",\"3_month_expense_coverage\",\"BK1\",\"I9\",\"I20\",\"I21_a\",\"affect_of_price_inc\",\"EF3_h\",\"EF5A\",\"EF7\",\"E2B\",\"ppeducat\",\"ppemploy\",\"ppfs1482\",\"atleast_okay\"]]\n",
    "y_class = df[\"target\"]\n",
    "\n",
    "categorical_features = [\"D1A\",\"3_month_expense_coverage\",\"BK1\",\"I9\",\"I20\",\"I21_a\",\"affect_of_price_inc\",\"EF3_h\",\"EF5A\",\"EF7\",\"E2B\",\"ppeducat\",\"ppemploy\",\"ppfs1482\",\"atleast_okay\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "X_class_transformed = transformer.fit_transform(X_class)\n",
    "\n",
    "class_df = pd.DataFrame(X_class_transformed)\n",
    "caseid_index = df.index\n",
    "class_df.index = caseid_index\n",
    "\n",
    "# XGBoost model\n",
    "xgb_class = xgb.XGBClassifier(random_state=10, n_estimators=1000, gamma=0.1, max_depth=3, learning_rate=0.1)\n",
    "probabilities = cross_val_predict(xgb_class, class_df, y_class, cv=5, method='predict_proba')\n",
    "predictions = cross_val_predict(xgb_class, class_df, y_class, cv=5)\n",
    "f1 = f1_score(y_class, predictions, average='micro')\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c565481f-ebc8-4f85-8f82-0e46b1cded8e",
    "outputId": "afa76e8d-203a-4822-f389-534037b9d85f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4a74ef3-82a7-4cfa-b7dd-48b8607405bc",
    "outputId": "c442f088-60bb-41d0-817f-8da63cf98bd1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sum of probabilities\n",
    "weights = [1, 2, 4, 8]\n",
    "weights = np.array(weights)\n",
    "weighted_proba = probabilities * weights\n",
    "weighted_sum = np.sum(weighted_proba, axis=1)\n",
    "\n",
    "df[\"weighted_sum\"] = weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_df = df[[\"distance_from_poverty\", \"distance_from_mean_income\", \"weighted_sum\"]]\n",
    "indicator_df = cudf.DataFrame.from_pandas(indicator_df)\n",
    "indicator_df = dask_cudf.from_cudf(indicator_df, npartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.DataFrame.from_pandas(df)\n",
    "df = dask_cudf.from_cudf(df, npartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.drop(columns=pdf.columns, inplace=True)\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(indicator_df))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9afeaf2d-b5b0-4b5a-8133-d45f13cb29cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Regression to calculate weighted sum based on income\n",
    "X_sum = df[[\"per_person_income\"]].astype(cp.float32)\n",
    "y_sum = indicator_df[\"weighted_sum\"].astype(cp.float32)\n",
    "X_sum_train, X_sum_test, y_sum_train, y_sum_test = train_test_split(X_sum, y_sum, test_size=0.2, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rfr_sum = cuRF(random_state=10, max_depth = 20, n_estimators=1000, min_samples_split=15, n_streams=1)\n",
    "rfr_sum.fit(X_sum_train, y_sum_train)\n",
    "fm_sum = rfr_sum.convert_to_fil_model(output_class=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_indicators(income):\n",
    "    #Indicators\n",
    "    poverty_line_2024 = 15060\n",
    "    distance_poverty_percent = (income / poverty_line_2024) * 100\n",
    "    \n",
    "    mean_income = 60168.54\n",
    "    distance_from_mean_income = (income / mean_income) * 100\n",
    "    \n",
    "    income_da = da.array([[income]])\n",
    "    income_da = income_da.compute()\n",
    "    weighted_sum = fm_sum.predict(income_da)\n",
    "    \n",
    "    return [distance_poverty_percent, distance_from_mean_income, weighted_sum[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "income = 10000\n",
    "test = predict_indicators(income)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73299a60-099e-4e55-9392-278400e46b11",
    "outputId": "62eb0c6c-999b-4b42-bb0f-4ca5295ea6fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "indicator_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4f7aeff4-a5a4-4639-9762-b1351d094f28"
   },
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7efcac29-9aa4-4814-a437-f8816d808846",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_indicator = indicator_df[[\"distance_from_poverty\", \"distance_from_mean_income\", \"weighted_sum\"]].astype(cp.float32)\n",
    "y = df['FSRI Score'].astype(cp.float32)\n",
    "X_indicator_train, X_indicator_test, y_train, y_test = train_test_split(X_indicator, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFR model\n",
    "rfr_indicator = cuRF(random_state=10, max_depth = 20, n_estimators=1000, min_samples_split=15, n_streams=1)\n",
    "rfr_indicator.fit(X_indicator_train, y_train)\n",
    "fm_indicator = rfr_indicator.convert_to_fil_model(output_class=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_indicator_test_da = X_indicator_test.compute()\n",
    "X_indicator_test_cp = X_indicator_test_da.to_cupy()\n",
    "y_pred_rfr_indicator = fm_indicator.predict(X_indicator_test_cp)\n",
    "\n",
    "y_test_da = y_test.compute()\n",
    "y_test_np = y_test_da.to_numpy()\n",
    "y_test_cp = y_test_da.to_numpy()\n",
    "y_pred_rfr_indicator_np = y_pred_rfr_indicator.get()\n",
    "\n",
    "r2_rfr_indicator = r2_score(y_test_np, y_pred_rfr_indicator_np)\n",
    "mae_rfr_indicator = mean_absolute_error(y_test_np, y_pred_rfr_indicator_np)\n",
    "mse_rfr_indicator = mean_squared_error(y_test_np, y_pred_rfr_indicator_np)\n",
    "\n",
    "print(f\"R2 (RF): {r2_rfr_indicator}\")\n",
    "print(f\"Mean Absolute Error (RF): {mae_rfr_indicator}\")\n",
    "print(f\"Mean Squared Error (RF): {mse_rfr_indicator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Model\n",
    "from cuml import Ridge\n",
    "rge_indicator = Ridge(alpha=100, output_type=\"cupy\", solver=\"svd\", fit_intercept=True)\n",
    "rge_indicator.fit(X_indicator_train, y_train)\n",
    "\n",
    "y_pred_rge_indicator = rge_indicator.predict(X_indicator_test_cp)\n",
    "y_pred_rge_indicator_np = y_pred_rge_indicator.get()\n",
    "\n",
    "r2_rge_indicator = r2_score(y_test_np, y_pred_rge_indicator_np)\n",
    "mae_rge_indicator = mean_absolute_error(y_test_np, y_pred_rge_indicator_np)\n",
    "mse_rge_indicator = mean_squared_error(y_test_np, y_pred_rge_indicator_np)\n",
    "\n",
    "print(f\"R2 (Ridge): {r2_rge_indicator}\")\n",
    "print(f\"Mean Absolute Error (Ridge): {mae_rge_indicator}\")\n",
    "print(f\"Mean Squared Error (Ridge): {mse_rge_indicator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_preds = (y_pred_rfr_indicator_np * 0.75) + (y_pred_rge_indicator_np * 0.25)\n",
    "r2_score_combined = r2_score(y_test_np, combined_preds)\n",
    "mae_score_combined = mean_absolute_error(y_test_np, combined_preds)\n",
    "mse_score_combined = mean_squared_error(y_test_np, combined_preds)\n",
    "\n",
    "print(f\"R2 (combined): {r2_score_combined}\")\n",
    "print(f\"Mean Absolute Error (combined): {mae_score_combined}\")\n",
    "print(f\"Mean Squared Error (combined): {mse_score_combined}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = df[\"per_person_income\"] \n",
    "per_person_inc = da.array(income)\n",
    "per_person_inc = per_person_inc.compute()\n",
    "type(per_person_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_indicators(income):\n",
    "    # Indicators\n",
    "    poverty_line_2024 = 15060\n",
    "    distance_poverty_percent = (income / poverty_line_2024) * 100\n",
    "    \n",
    "    mean_income = 60168.54\n",
    "    distance_from_mean_income = (income / mean_income) * 100\n",
    "    \n",
    "    weighted_sum = fm_sum.predict(cp.array([[income]], dtype=cp.float32))\n",
    "    return [distance_poverty_percent, distance_from_mean_income, weighted_sum[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def final_score_calc(per_person_inc):\n",
    "    final_preds = []\n",
    "    for inc in per_person_inc:\n",
    "        indicators = predict_indicators(inc)\n",
    "        indicator_cp = cp.array([indicators], dtype=cp.float32)\n",
    "        final_pred1 = fm_indicator.predict(indicator_cp)\n",
    "        final_pred2 = rge_indicator.predict(indicator_cp)\n",
    "        final_pred = (final_pred1 * 0.75) + (final_pred2 * 0.25)\n",
    "        final_preds.append(final_pred)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "income = df[\"per_person_income\"] \n",
    "per_person_inc = da.array(income)\n",
    "per_person_inc = per_person_inc.compute()\n",
    "original_FSRI = final_score_calc(per_person_inc)\n",
    "len(original_FSRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_FSRI_cp = cp.array(original_FSRI)\n",
    "original_FSRI_np = original_FSRI_cp.get()\n",
    "pdf[\"original_FSRI\"] = 0\n",
    "pdf[\"original_FSRI\"] = original_FSRI_np\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4859f5d-4f6b-43ac-a00f-576488327545"
   },
   "outputs": [],
   "source": [
    "# THE GENETIC ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "262e84ef-1436-43c0-983a-7add9516922f",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup for fitness func\n",
    "\n",
    "gene_space = [20592000000.0, 21621600000.0, 22651200000.0, 23680800000.0, 24710400000.0, 25740000000.0, 26769600000.0, 27799200000.0, 28828800000.0, 29858400000.0, 30888000000]\n",
    "# Setting the ranges of the min and max that each decile can receive, (no more/less than 20% of an equal per capita dividend distribution scenario)\n",
    "\n",
    "total_rev = 257400000000 #Total revenue generated from the carbon tax, CBO estimates\n",
    "\n",
    "amount_of_ppl_in_decile = 34200000\n",
    "\n",
    "# Based off of updated burden calculations (repurposed from Fremstad & Paul 2019)\n",
    "    \n",
    "# The following were generated from Anders Fremstad's \"The Impact of a Carbon Tax on Inequality\".\n",
    "# I edited & updated these programs to fit my specific scenario and regenerated the results. These regenerated results served as some of the inputs into my genetic algorithm.\n",
    "\n",
    "increased_costs_actual = [488.53, 582.45, 722.86, 776.35, 843.54, 941.06, 1027.09, 1144.42, 1261.38, 1528.00] # Estimated costs per decile (in ascending decile order). Average amount that each decile is expected to have to pay in increased prices in 2024 dollars.\n",
    "# By individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = df[\"per_person_income\"] \n",
    "original_income = income.compute()\n",
    "original_income = original_income.to_pandas()\n",
    "\n",
    "decile = df[\"decile\"]\n",
    "decile = decile.compute()\n",
    "decile = decile.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness value for equal dividends\n",
    "\n",
    "def fitness_func_benchmark(test_solution):\n",
    "\n",
    "    # Objectives 1, 2, & 3 - Maximizing FSRI Score\n",
    "\n",
    "    def dividend_income():\n",
    "        new_fsri = []\n",
    "        for inc, dec in zip(original_income, decile):\n",
    "            dividend_income = test_solution[dec - 1] / amount_of_ppl_in_decile  # Adjusting for zero-indexing\n",
    "            dividend_net = dividend_income - increased_costs_actual[dec - 1]\n",
    "            tot_income = inc + dividend_net\n",
    "            new_fsri.append(tot_income)\n",
    "        return new_fsri\n",
    "\n",
    "    total_incomes = dividend_income()\n",
    "\n",
    "    per_person_inc = cp.array(total_incomes)\n",
    "    new_FSRI = final_score_calc(per_person_inc)\n",
    "\n",
    "    new_FSRI_cp = cp.array(new_FSRI)\n",
    "    new_FSRI_np = new_FSRI_cp.get()\n",
    "    pdf[\"new_FSRI\"] = new_FSRI_np\n",
    "    pdf.head()\n",
    "\n",
    "    pdf[\"FSRI_diff\"] = pdf[\"new_FSRI\"] - pdf[\"original_FSRI\"]\n",
    "    pdf[\"decile\"] = decile\n",
    "    \n",
    "    fitness1 = np.mean(pdf[\"FSRI_diff\"])\n",
    "\n",
    "    mean_bottom_half = pdf.loc[pdf['decile'] <= 5, \"FSRI_diff\"].mean()\n",
    "    fitness2 = mean_bottom_half\n",
    "\n",
    "    mean_top_half = pdf.loc[pdf['decile'] > 5, \"FSRI_diff\"].mean()\n",
    "    fitness3 = mean_top_half\n",
    "    \n",
    "    # Penalty for not adding up to total_rev\n",
    "    # Added because I want the algorithm to gurantee the use of all of the funds to decrease the time until convergence.\n",
    "\n",
    "    deviation = abs(np.sum(test_solution) - total_rev)\n",
    "    penalty_rate = 1000\n",
    "    penalty = deviation * penalty_rate\n",
    "\n",
    "    fitness1 -= penalty\n",
    "    fitness2 -= penalty\n",
    "    fitness3 -= penalty\n",
    "\n",
    "    return [fitness1, fitness2, fitness3]\n",
    "\n",
    "test_solution = [25740000000, 25740000000, 25740000000, 25740000000, 25740000000, 25740000000, 25740000000, 25740000000, 25740000000, 25740000000]\n",
    "benchmark = fitness_func_benchmark(test_solution)\n",
    "print(f\"benchmark score (equal dividends) {benchmark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[\"decile\"] = decile\n",
    "pdf[\"per_person_income\"] = original_income\n",
    "pdf[\"original_FSRI\"] = pdf[\"original_FSRI\"]\n",
    "pdf[\"equal_new_FSRI\"] = pdf[\"new_FSRI\"]\n",
    "pdf[\"equal_FSRI_diff\"] = pdf[\"equal_new_FSRI\"] - pdf[\"original_FSRI\"]\n",
    "pdf = pdf.drop(columns = [\"new_FSRI\", \"FSRI_diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7815af23-e8c8-43dd-8355-0bb10506fc51",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The fitness func\n",
    "\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "\n",
    "    # Objectives 1, 2, & 3 - Maximizing FSRI Score\n",
    "\n",
    "    def dividend_income():\n",
    "        new_fsri = []\n",
    "        for inc, dec in zip(original_income, decile):\n",
    "            dividend_income = solution[dec - 1] / amount_of_ppl_in_decile  # Adjusting for zero-indexing\n",
    "            dividend_net = dividend_income - increased_costs_actual[dec - 1]\n",
    "            tot_income = inc + dividend_net\n",
    "            new_fsri.append(tot_income)\n",
    "        return new_fsri\n",
    "\n",
    "    total_incomes = dividend_income()\n",
    "\n",
    "    per_person_inc = cp.array(total_incomes)\n",
    "    new_FSRI = final_score_calc(per_person_inc)\n",
    "\n",
    "    new_FSRI_cp = cp.array(new_FSRI)\n",
    "    new_FSRI_np = new_FSRI_cp.get()\n",
    "    pdf[\"new_FSRI\"] = 0\n",
    "    pdf[\"new_FSRI\"] = new_FSRI_np\n",
    "    pdf.head()\n",
    "\n",
    "    pdf[\"FSRI_diff\"] = pdf[\"new_FSRI\"] - pdf[\"original_FSRI\"]\n",
    "    pdf[\"decile\"] = decile\n",
    "    \n",
    "    fitness1 = np.mean(pdf[\"FSRI_diff\"])\n",
    "\n",
    "    mean_bottom_half = pdf.loc[pdf['decile'] <= 5, \"FSRI_diff\"].mean()\n",
    "    fitness2 = mean_bottom_half\n",
    "\n",
    "    mean_top_half = pdf.loc[pdf['decile'] > 5, \"FSRI_diff\"].mean()\n",
    "    fitness3 = mean_top_half\n",
    "    \n",
    "    # Penalty for not adding up to total_rev\n",
    "    # Added because I want the algorithm to gurantee the use of all of the funds to decrease the time until convergence.\n",
    "\n",
    "    deviation = abs(np.sum(solution) - total_rev)\n",
    "    penalty_rate = 1000\n",
    "    penalty = deviation * penalty_rate\n",
    "\n",
    "    fitness1 -= penalty\n",
    "    fitness2 -= penalty\n",
    "    fitness3 -= penalty\n",
    "\n",
    "    return [fitness1, fitness2, fitness3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mutation(offspring, ga_instance):\n",
    "    for chromosome_idx in range(offspring.shape[0]):\n",
    "        random_gene_idx = np.random.choice(range(offspring.shape[1]))\n",
    "        old_value = offspring[chromosome_idx, random_gene_idx]\n",
    "        new_value = np.random.choice(gene_space)\n",
    "        difference = new_value - old_value\n",
    "        offspring[chromosome_idx, random_gene_idx] = new_value\n",
    "        \n",
    "        valid_other_gene_indices = None\n",
    "        if difference >= 0:\n",
    "            valid_other_gene_indices = [i for i in range(offspring.shape[1]) if i != random_gene_idx and offspring[chromosome_idx, i] - difference >= min(gene_space)]\n",
    "        else:\n",
    "            valid_other_gene_indices = [i for i in range(offspring.shape[1]) if i != random_gene_idx and offspring[chromosome_idx, i] - difference <= max(gene_space)]\n",
    "\n",
    "        if not valid_other_gene_indices:\n",
    "            offspring[chromosome_idx, random_gene_idx] = old_value\n",
    "            continue\n",
    "            \n",
    "        other_gene_idx = np.random.choice(valid_other_gene_indices)\n",
    "        new_other_value = offspring[chromosome_idx, other_gene_idx] - difference\n",
    "        offspring[chromosome_idx, other_gene_idx] = new_other_value\n",
    "        \n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Parameters of the GA\n",
    "\n",
    "initial_gene_value = 25740000000\n",
    "initial_population = np.full((5, 10), initial_gene_value)\n",
    "\n",
    "def on_gen(ga_instance):\n",
    "    print(\"Generation : \", ga_instance.generations_completed)\n",
    "    print(\"Fitness of the best solution :\", ga_instance.best_solution()[1])\n",
    "    print(f\"Best Solution: {ga_instance.best_solution()[0]}\")\n",
    "\n",
    "ga_instance = pygad.GA(fitness_func = fitness_func,\n",
    "                       num_generations = 500,\n",
    "                       num_parents_mating = 3,\n",
    "                       sol_per_pop = 5,\n",
    "                       num_genes = 10,\n",
    "                       gene_space = gene_space,\n",
    "                       parent_selection_type = \"tournament_nsga2\",\n",
    "                       crossover_type= \"scattered\",\n",
    "                       crossover_probability= 0.5,\n",
    "                       mutation_type=custom_mutation,\n",
    "                       mutation_probability = 0.10,\n",
    "                       random_seed = 10,\n",
    "                       on_generation = on_gen,\n",
    "                       allow_duplicate_genes=True,\n",
    "                       initial_population = initial_population\n",
    "                       )\n",
    "\n",
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance.plot_fitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "91299abe-18e8-4570-902c-6f6c18860dea",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_solution, best_solution_fitness, best_solution_idx = ga_instance.best_solution()\n",
    "print(f\"Best Solution: {best_solution}\")\n",
    "print(f\"Best Solution Fitness: {best_solution_fitness}\")\n",
    "\n",
    "if ga_instance.best_solution_generation != -1:\n",
    "    print(f\"Best fitness value reached after {ga_instance.best_solution_generation} generations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the income and FSRI difference for the new solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA_best_solution = ', '.join(map(str, best_solution))\n",
    "GA_best_solution = [float(x) for x in GA_best_solution.replace(\" \", \"\").split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA New FSRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fitness_func_benchmark(test_solution):\n",
    "\n",
    "    # Objectives 1, 2, & 3 - Maximizing FSRI Score\n",
    "\n",
    "    def dividend_income():\n",
    "        new_fsri = []\n",
    "        for inc, dec in zip(original_income, decile):\n",
    "            dividend_income = test_solution[dec - 1] / amount_of_ppl_in_decile  # Adjusting for zero-indexing\n",
    "            dividend_net = dividend_income - increased_costs_actual[dec - 1]\n",
    "            tot_income = inc + dividend_net\n",
    "            new_fsri.append(tot_income)\n",
    "        return new_fsri\n",
    "\n",
    "    total_incomes = dividend_income()\n",
    "\n",
    "    per_person_inc = cp.array(total_incomes)\n",
    "    new_FSRI = final_score_calc(per_person_inc)\n",
    "\n",
    "    new_FSRI_cp = cp.array(new_FSRI)\n",
    "    new_FSRI_np = new_FSRI_cp.get()\n",
    "    pdf[\"GA_new_FSRI\"] = new_FSRI_np\n",
    "    pdf.head()\n",
    "\n",
    "    pdf[\"GA_FSRI_diff\"] = pdf[\"GA_new_FSRI\"] - pdf[\"original_FSRI\"]\n",
    "    pdf[\"decile\"] = decile\n",
    "    \n",
    "    fitness1 = np.mean(pdf[\"GA_FSRI_diff\"])\n",
    "\n",
    "    mean_bottom_half = pdf.loc[pdf['decile'] <= 5, \"GA_FSRI_diff\"].mean()\n",
    "    fitness2 = mean_bottom_half\n",
    "\n",
    "    mean_top_half = pdf.loc[pdf['decile'] > 5, \"GA_FSRI_diff\"].mean()\n",
    "    fitness3 = mean_top_half\n",
    "    \n",
    "    # Penalty for not adding up to total_rev\n",
    "    # Added because I want the algorithm to gurantee the use of all of the funds to decrease the time until convergence.\n",
    "\n",
    "    deviation = abs(np.sum(test_solution) - total_rev)\n",
    "    penalty_rate = 1000\n",
    "    penalty = deviation * penalty_rate\n",
    "\n",
    "    fitness1 -= penalty\n",
    "    fitness2 -= penalty\n",
    "    fitness3 -= penalty\n",
    "\n",
    "    return [fitness1, fitness2, fitness3]\n",
    "\n",
    "test_solution = GA_best_solution\n",
    "score = fitness_func_benchmark(test_solution)\n",
    "print(f\"GA solution score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[\"GA_new_FSRI\"] = pdf[\"GA_new_FSRI\"]\n",
    "pdf[\"GA_FSRI_diff\"] = pdf[\"GA_new_FSRI\"] - pdf[\"original_FSRI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = r\"C:\\Users\\...\\Carbon_Dividend_Analysis\\Data\\Dividend_Data.xlsx\"\n",
    "pdf.to_excel(output_file_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5236233,
     "sourceId": 8725222,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
